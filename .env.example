# The Human - Environment Configuration
# Copy this file to .env.local for development or set these in Vercel for production

# ==============================================================================
# APPLICATION SETTINGS
# ==============================================================================

# App URL - Used for generating magic links and sharing
# Development: http://localhost:3000
# Production: https://your-app.vercel.app
NEXT_PUBLIC_APP_URL=http://localhost:3000

# Share key for magic link token signing (REQUIRED)
# Generate a secure random string for production
# You can use: openssl rand -base64 32
SHARE_KEY=your-secure-share-key-here

# Node environment
NODE_ENV=development

# ==============================================================================
# LLM PROVIDER CONFIGURATION
# ==============================================================================

# LLM Provider Selection (claude|gemini|openai)
LLM_PROVIDER=claude

# Anthropic Claude Configuration (default provider)
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-api03-your-api-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_MAX_TOKENS=8000
ANTHROPIC_TIMEOUT=30000

# Google Vertex AI Configuration (if LLM_PROVIDER=gemini)
# Get your credentials from: https://cloud.google.com/vertex-ai
GOOGLE_VERTEX_KEY=your-vertex-api-key-here
GOOGLE_API_KEY=your-google-api-key-here

# OpenAI Configuration (if LLM_PROVIDER=openai)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# ==============================================================================
# STORAGE CONFIGURATION
# ==============================================================================

# Storage Driver Selection (vercel-blob|s3|fs)
STORAGE_DRIVER=vercel-blob

# Vercel Blob Storage (recommended for Vercel deployments)
# Auto-provided by Vercel Blob addon or create at: https://vercel.com/docs/storage/vercel-blob
VERCEL_BLOB_READ_WRITE_TOKEN=vercel_blob_rw_your-token-here

# AWS S3 Storage (if STORAGE_DRIVER=s3)
# Get credentials from: https://aws.amazon.com/s3/
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_S3_BUCKET=your-s3-bucket-name
AWS_REGION=us-east-1

# ==============================================================================
# OPTIONAL SERVICES
# ==============================================================================

# ElevenLabs TTS Service (enables Audiobook Mode)
# Get your API key from: https://elevenlabs.io/
ELEVENLABS_API_KEY=your-elevenlabs-api-key-here

# Assistant Configuration
MAX_DAILY_TOKENS=250000
MAX_RPM=10

# ==============================================================================
# DEPLOYMENT AND BUILD CONFIGURATION
# ==============================================================================

# Deployment Configuration
DEPLOY_AUTO_PREWARM=true
HEALTH_INCLUDE_QUALITY=false

# Build Metadata (auto-provided by Vercel)
VERCEL_GIT_COMMIT_SHA=auto-provided
VERCEL_GIT_COMMIT_MESSAGE=auto-provided
VERCEL_ENV=auto-provided
VERCEL_URL=auto-provided

# ==============================================================================
# SECURITY AND RATE LIMITING
# ==============================================================================

# Rate limiting (requests per minute)
RATE_LIMIT_RPM=60

# Maximum token lifetime (hours)
MAX_TOKEN_LIFETIME=168

# Enable debug logging
DEBUG=false

# ==============================================================================
# PWA AND FEATURES
# ==============================================================================

# Enable PWA features
NEXT_PUBLIC_PWA_ENABLED=true

# Enable analytics (if you add analytics)
NEXT_PUBLIC_ANALYTICS_ID=

# Enable error reporting (if you add Sentry, etc.)
SENTRY_DSN=

# ==============================================================================
# LEGACY CONFIGURATION (for migration from previous version)
# ==============================================================================

# NextAuth.js Configuration (if migrating from NextAuth)
NEXTAUTH_SECRET=your-nextauth-secret-here
NEXTAUTH_URL=http://localhost:3000

# Email Service Configuration (if migrating from email-based sharing)
EMAIL_SERVICE=resend
EMAIL_SERVICE_API_KEY=your-email-api-key-here
FROM_EMAIL=noreply@your-domain.com
FROM_NAME=The Human

# Vercel KV Storage (if migrating from KV-based token storage)
KV_URL=redis://localhost:6379
KV_REST_API_URL=https://your-kv-url.kv.vercel-storage.com
KV_REST_API_TOKEN=your-kv-token
KV_REST_API_READ_ONLY_TOKEN=your-kv-readonly-token

# CORS Configuration (if needed for API access)
ALLOWED_ORIGINS=http://localhost:3000,https://your-domain.com

# ==============================================================================
# DEPLOYMENT NOTES - ONE-COMMAND DEPLOYMENT
# ==============================================================================

# For Vercel deployment with new system:
# 1. Install Vercel CLI: npm i -g vercel
# 2. Link project: vercel link
# 3. Set environment variables: vercel env add
# 4. Deploy preview: npm run deploy:preview
# 5. Deploy production: npm run deploy:prod

# Environment validation:
# npm run env:check          # Check current environment
# npm run env:check:prod     # Validate production environment
# npm run env:check:vercel   # Validate Vercel-specific settings

# Health monitoring:
# GET /api/health            # Basic health check
# GET /api/health?detailed   # Full diagnostic information
# GET /api/health?quality    # Quality gates and deployment readiness

# Required secrets for CI/CD:
# VERCEL_TOKEN              # Vercel authentication token
# VERCEL_ORG_ID            # Vercel organization ID
# VERCEL_PROJECT_ID        # Vercel project ID

# ==============================================================================
# DEVELOPMENT SETUP
# ==============================================================================

# Local development:
# 1. Copy this file to .env.local
# 2. Set required variables (SHARE_KEY, ANTHROPIC_API_KEY, VERCEL_BLOB_READ_WRITE_TOKEN)
# 3. Run: npm run dev

# Testing different providers:
# LLM_PROVIDER=claude       # Use Anthropic Claude (default)
# LLM_PROVIDER=gemini       # Use Google Vertex AI
# LLM_PROVIDER=openai       # Use OpenAI

# Testing different storage:
# STORAGE_DRIVER=vercel-blob # Use Vercel Blob (default)
# STORAGE_DRIVER=s3          # Use AWS S3
# STORAGE_DRIVER=fs          # Use local filesystem (dev only)

# ==============================================================================
# QUALITY GATES AND MONITORING
# ==============================================================================

# Quality Gates Configuration (optional)
QUALITY_MIN_LPR=0.90
QUALITY_MIN_COVERAGE=0.85
QUALITY_ENFORCE_GATES=false

# Monitoring Configuration
HEALTH_CHECK_INTERVAL=30000
DEPLOYMENT_TIMEOUT=300000

# ==============================================================================
# SECURITY CHECKLIST
# ==============================================================================

# Security checklist:
# ✓ Use strong, unique secrets for SHARE_KEY
# ✓ Configure LLM provider API keys securely
# ✓ Set up storage driver with proper credentials
# ✓ Enable HTTPS in production (automatic with Vercel)
# ✓ Configure proper environment variable validation
# ✓ Set up health monitoring and alerting
# ✓ Use environment variables, never commit secrets to git
# ✓ Regularly rotate API keys and tokens
# ✓ Monitor deployment health and quality gates

# Generate secure secrets:
# openssl rand -base64 32    # Generate SHARE_KEY (256-bit)
# uuidgen                    # Generate UUID for additional entropy

# ==============================================================================
# TROUBLESHOOTING
# ==============================================================================

# Common issues and solutions:

# Environment validation failures:
# 1. Check required variables are set: npm run env:check:prod
# 2. Verify API keys are valid and have proper permissions
# 3. Ensure storage credentials are configured correctly

# Health check failures:
# 1. Test health endpoint: curl /api/health?detailed=true
# 2. Check LLM provider connectivity
# 3. Verify storage driver accessibility
# 4. Review quality gates status

# Deployment failures:
# 1. Run build validation: npm run build:validate
# 2. Check deployment logs: vercel logs
# 3. Verify all environment variables are set
# 4. Test locally first: npm run dev

# Storage issues:
# 1. Test storage connectivity in health endpoint
# 2. Verify credentials and permissions
# 3. Check regional configuration for S3
# 4. Ensure blob storage quota is sufficient

# LLM provider issues:
# 1. Verify API key validity
# 2. Check rate limits and quotas
# 3. Test different models if available
# 4. Review provider-specific documentation